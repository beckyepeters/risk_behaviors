{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97bd599f-d070-4079-a14e-95f3b2e0fd9e",
   "metadata": {},
   "source": [
    "#### Modeling the YRBSS: Target Q 58; Sex behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9a13132-2cad-4d03-adf2-2ce2b4c7ed60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import model_selection \n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, f1_score, recall_score\n",
    "\n",
    "# from scipy.stats import \n",
    "# import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef2993af-add2-487e-98fa-7a8cea65b912",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex = pd.read_csv('data/sex.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a04efae-67f3-4b91-8a32-d29e3e88bddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sex.q58.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0eb7f348-4c38-4120-80e2-8343c8136d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex.drop(columns='sitename', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc68522f-1a62-4094-a755-5eac2b626eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.623655\n",
       "1.0    0.376345\n",
       "Name: q58, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sex.q58.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e76fcf6-e298-494b-b72d-f98130094ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = sex.pop('q58')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f470812e-6eeb-4278-9f28-a86ae58ffa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sex.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "96cac472-198b-4da0-a892-3c8041930c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7ae880ab-3164-4d08-8618-0b2af3368dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((188784, 27), (47196, 27), (188784,), (47196,))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f6588ac-f755-45bc-adf1-6df83a5f20de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3763454530044919, 0.3763454530044919)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.sum() / len(X_train), y_test.sum() / len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f589abd1-8a33-4396-b16f-16a9005cf904",
   "metadata": {},
   "source": [
    "Source for the run_experiments code: https://towardsdatascience.com/quickly-test-multiple-models-a98477476f0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f2ad6e96-9e79-41a3-bebf-11f97c573596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments(X_train: pd.DataFrame, y_train: pd.DataFrame, \n",
    "                   X_test: pd.DataFrame, y_test: pd.DataFrame) -> pd.DataFrame: \n",
    "    dfs = []\n",
    "    models = [\n",
    "        ('LogReg', LogisticRegression()),\n",
    "        ('RF', RandomForestClassifier()), \n",
    "        ('KNN', KNeighborsClassifier()), \n",
    "        ('SVM', SVC()), \n",
    "        ('GNB', GaussianNB()), \n",
    "        ('XGB', XGBClassifier())\n",
    "    ]\n",
    "    results = []\n",
    "    names = []\n",
    "    scoring = ['accuracy', 'precision_weighted', 'recall_weighted', \n",
    "               'f1_weighted', 'roc_auc']\n",
    "    target_names = ['Never Had Sex', 'Have Had Sex']\n",
    "    for name, model in models: \n",
    "        kfold = model_selection.KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        cv_results = model_selection.cross_validate(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "        clf = model.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(name)\n",
    "        print(classification_report(y_test, y_pred, \n",
    "                                   target_names = target_names))\n",
    "        results.append(cv_results)\n",
    "        this_df = pd.DataFrame(cv_results)\n",
    "        this_df['model'] = name\n",
    "        dfs.append(this_df)\n",
    "    \n",
    "    final = pd.concat(dfs, ignore_index=True)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6006c8d-94c0-4864-b969-c0b22a25ac80",
   "metadata": {},
   "source": [
    "DO NOT RERUN NEXT CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5408e9cd-a3d4-416d-9390-2e216fb0afd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Never Had Sex       0.76      0.86      0.81     29434\n",
      " Have Had Sex       0.71      0.56      0.63     17762\n",
      "\n",
      "     accuracy                           0.75     47196\n",
      "    macro avg       0.74      0.71      0.72     47196\n",
      " weighted avg       0.75      0.75      0.74     47196\n",
      "\n",
      "RF\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Never Had Sex       0.85      0.88      0.87     29434\n",
      " Have Had Sex       0.79      0.75      0.77     17762\n",
      "\n",
      "     accuracy                           0.83     47196\n",
      "    macro avg       0.82      0.81      0.82     47196\n",
      " weighted avg       0.83      0.83      0.83     47196\n",
      "\n",
      "KNN\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Never Had Sex       0.77      0.85      0.81     29434\n",
      " Have Had Sex       0.69      0.58      0.63     17762\n",
      "\n",
      "     accuracy                           0.75     47196\n",
      "    macro avg       0.73      0.71      0.72     47196\n",
      " weighted avg       0.74      0.75      0.74     47196\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Never Had Sex       0.62      1.00      0.77     29434\n",
      " Have Had Sex       0.00      0.00      0.00     17762\n",
      "\n",
      "     accuracy                           0.62     47196\n",
      "    macro avg       0.31      0.50      0.38     47196\n",
      " weighted avg       0.39      0.62      0.48     47196\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNB\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Never Had Sex       0.71      0.89      0.79     29434\n",
      " Have Had Sex       0.70      0.40      0.51     17762\n",
      "\n",
      "     accuracy                           0.71     47196\n",
      "    macro avg       0.70      0.65      0.65     47196\n",
      " weighted avg       0.71      0.71      0.69     47196\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:32:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:32:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:32:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:33:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:33:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:33:21] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGB\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Never Had Sex       0.80      0.85      0.82     29434\n",
      " Have Had Sex       0.72      0.64      0.68     17762\n",
      "\n",
      "     accuracy                           0.77     47196\n",
      "    macro avg       0.76      0.75      0.75     47196\n",
      " weighted avg       0.77      0.77      0.77     47196\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision_weighted</th>\n",
       "      <th>test_recall_weighted</th>\n",
       "      <th>test_f1_weighted</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.197611</td>\n",
       "      <td>0.078982</td>\n",
       "      <td>0.753211</td>\n",
       "      <td>0.749312</td>\n",
       "      <td>0.753211</td>\n",
       "      <td>0.744835</td>\n",
       "      <td>0.815798</td>\n",
       "      <td>LogReg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.256970</td>\n",
       "      <td>0.072492</td>\n",
       "      <td>0.750377</td>\n",
       "      <td>0.747260</td>\n",
       "      <td>0.750377</td>\n",
       "      <td>0.742554</td>\n",
       "      <td>0.817177</td>\n",
       "      <td>LogReg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.323152</td>\n",
       "      <td>0.076410</td>\n",
       "      <td>0.754800</td>\n",
       "      <td>0.750927</td>\n",
       "      <td>0.754800</td>\n",
       "      <td>0.747452</td>\n",
       "      <td>0.815897</td>\n",
       "      <td>LogReg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.365336</td>\n",
       "      <td>0.070918</td>\n",
       "      <td>0.752576</td>\n",
       "      <td>0.748896</td>\n",
       "      <td>0.752576</td>\n",
       "      <td>0.744790</td>\n",
       "      <td>0.818429</td>\n",
       "      <td>LogReg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.184873</td>\n",
       "      <td>0.071686</td>\n",
       "      <td>0.751907</td>\n",
       "      <td>0.747581</td>\n",
       "      <td>0.751907</td>\n",
       "      <td>0.744372</td>\n",
       "      <td>0.815377</td>\n",
       "      <td>LogReg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18.441650</td>\n",
       "      <td>2.263808</td>\n",
       "      <td>0.818206</td>\n",
       "      <td>0.816985</td>\n",
       "      <td>0.818206</td>\n",
       "      <td>0.817390</td>\n",
       "      <td>0.888723</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19.470484</td>\n",
       "      <td>2.328132</td>\n",
       "      <td>0.818550</td>\n",
       "      <td>0.817093</td>\n",
       "      <td>0.818550</td>\n",
       "      <td>0.817271</td>\n",
       "      <td>0.888333</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19.132283</td>\n",
       "      <td>2.177924</td>\n",
       "      <td>0.818947</td>\n",
       "      <td>0.817565</td>\n",
       "      <td>0.818947</td>\n",
       "      <td>0.817934</td>\n",
       "      <td>0.888986</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17.576935</td>\n",
       "      <td>2.067484</td>\n",
       "      <td>0.816882</td>\n",
       "      <td>0.815295</td>\n",
       "      <td>0.816882</td>\n",
       "      <td>0.815563</td>\n",
       "      <td>0.888003</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17.318675</td>\n",
       "      <td>2.014958</td>\n",
       "      <td>0.815129</td>\n",
       "      <td>0.813811</td>\n",
       "      <td>0.815129</td>\n",
       "      <td>0.814233</td>\n",
       "      <td>0.887621</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.058219</td>\n",
       "      <td>213.654598</td>\n",
       "      <td>0.743703</td>\n",
       "      <td>0.738761</td>\n",
       "      <td>0.743703</td>\n",
       "      <td>0.738541</td>\n",
       "      <td>0.791959</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.055141</td>\n",
       "      <td>207.019040</td>\n",
       "      <td>0.741929</td>\n",
       "      <td>0.737579</td>\n",
       "      <td>0.741929</td>\n",
       "      <td>0.735912</td>\n",
       "      <td>0.792203</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.028616</td>\n",
       "      <td>210.869691</td>\n",
       "      <td>0.741690</td>\n",
       "      <td>0.736748</td>\n",
       "      <td>0.741690</td>\n",
       "      <td>0.736258</td>\n",
       "      <td>0.790189</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.030084</td>\n",
       "      <td>208.075756</td>\n",
       "      <td>0.741002</td>\n",
       "      <td>0.736173</td>\n",
       "      <td>0.741002</td>\n",
       "      <td>0.735659</td>\n",
       "      <td>0.789650</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.029520</td>\n",
       "      <td>206.730745</td>\n",
       "      <td>0.741207</td>\n",
       "      <td>0.736068</td>\n",
       "      <td>0.741207</td>\n",
       "      <td>0.735671</td>\n",
       "      <td>0.787422</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5472.215316</td>\n",
       "      <td>936.811892</td>\n",
       "      <td>0.626798</td>\n",
       "      <td>0.392875</td>\n",
       "      <td>0.626798</td>\n",
       "      <td>0.483005</td>\n",
       "      <td>0.804013</td>\n",
       "      <td>SVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1953.427183</td>\n",
       "      <td>916.618272</td>\n",
       "      <td>0.617316</td>\n",
       "      <td>0.381079</td>\n",
       "      <td>0.617316</td>\n",
       "      <td>0.471249</td>\n",
       "      <td>0.804780</td>\n",
       "      <td>SVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1870.938029</td>\n",
       "      <td>886.188605</td>\n",
       "      <td>0.624626</td>\n",
       "      <td>0.390158</td>\n",
       "      <td>0.624626</td>\n",
       "      <td>0.480304</td>\n",
       "      <td>0.804062</td>\n",
       "      <td>SVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1880.450427</td>\n",
       "      <td>907.604548</td>\n",
       "      <td>0.622851</td>\n",
       "      <td>0.387944</td>\n",
       "      <td>0.622851</td>\n",
       "      <td>0.478102</td>\n",
       "      <td>0.807386</td>\n",
       "      <td>SVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1885.683136</td>\n",
       "      <td>931.922788</td>\n",
       "      <td>0.626682</td>\n",
       "      <td>0.392730</td>\n",
       "      <td>0.626682</td>\n",
       "      <td>0.482860</td>\n",
       "      <td>0.803322</td>\n",
       "      <td>SVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.244333</td>\n",
       "      <td>0.115375</td>\n",
       "      <td>0.715338</td>\n",
       "      <td>0.713277</td>\n",
       "      <td>0.715338</td>\n",
       "      <td>0.693197</td>\n",
       "      <td>0.796196</td>\n",
       "      <td>GNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.118036</td>\n",
       "      <td>0.101084</td>\n",
       "      <td>0.707842</td>\n",
       "      <td>0.707115</td>\n",
       "      <td>0.707842</td>\n",
       "      <td>0.685745</td>\n",
       "      <td>0.791974</td>\n",
       "      <td>GNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.113713</td>\n",
       "      <td>0.098512</td>\n",
       "      <td>0.711285</td>\n",
       "      <td>0.709215</td>\n",
       "      <td>0.711285</td>\n",
       "      <td>0.688589</td>\n",
       "      <td>0.794803</td>\n",
       "      <td>GNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.118754</td>\n",
       "      <td>0.100632</td>\n",
       "      <td>0.709511</td>\n",
       "      <td>0.707365</td>\n",
       "      <td>0.709511</td>\n",
       "      <td>0.687073</td>\n",
       "      <td>0.793973</td>\n",
       "      <td>GNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.117454</td>\n",
       "      <td>0.096788</td>\n",
       "      <td>0.710748</td>\n",
       "      <td>0.707504</td>\n",
       "      <td>0.710748</td>\n",
       "      <td>0.688273</td>\n",
       "      <td>0.791422</td>\n",
       "      <td>GNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6.889153</td>\n",
       "      <td>0.114615</td>\n",
       "      <td>0.774532</td>\n",
       "      <td>0.771249</td>\n",
       "      <td>0.774532</td>\n",
       "      <td>0.771316</td>\n",
       "      <td>0.842409</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7.411511</td>\n",
       "      <td>0.135232</td>\n",
       "      <td>0.773234</td>\n",
       "      <td>0.770320</td>\n",
       "      <td>0.773234</td>\n",
       "      <td>0.769731</td>\n",
       "      <td>0.844397</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7.263801</td>\n",
       "      <td>0.139516</td>\n",
       "      <td>0.773790</td>\n",
       "      <td>0.770620</td>\n",
       "      <td>0.773790</td>\n",
       "      <td>0.770719</td>\n",
       "      <td>0.843720</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>7.142239</td>\n",
       "      <td>0.134219</td>\n",
       "      <td>0.774770</td>\n",
       "      <td>0.771628</td>\n",
       "      <td>0.774770</td>\n",
       "      <td>0.771337</td>\n",
       "      <td>0.844614</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7.350236</td>\n",
       "      <td>0.123278</td>\n",
       "      <td>0.772645</td>\n",
       "      <td>0.769385</td>\n",
       "      <td>0.772645</td>\n",
       "      <td>0.769632</td>\n",
       "      <td>0.842041</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
       "0      1.197611    0.078982       0.753211                 0.749312   \n",
       "1      1.256970    0.072492       0.750377                 0.747260   \n",
       "2      1.323152    0.076410       0.754800                 0.750927   \n",
       "3      1.365336    0.070918       0.752576                 0.748896   \n",
       "4      1.184873    0.071686       0.751907                 0.747581   \n",
       "5     18.441650    2.263808       0.818206                 0.816985   \n",
       "6     19.470484    2.328132       0.818550                 0.817093   \n",
       "7     19.132283    2.177924       0.818947                 0.817565   \n",
       "8     17.576935    2.067484       0.816882                 0.815295   \n",
       "9     17.318675    2.014958       0.815129                 0.813811   \n",
       "10     0.058219  213.654598       0.743703                 0.738761   \n",
       "11     0.055141  207.019040       0.741929                 0.737579   \n",
       "12     0.028616  210.869691       0.741690                 0.736748   \n",
       "13     0.030084  208.075756       0.741002                 0.736173   \n",
       "14     0.029520  206.730745       0.741207                 0.736068   \n",
       "15  5472.215316  936.811892       0.626798                 0.392875   \n",
       "16  1953.427183  916.618272       0.617316                 0.381079   \n",
       "17  1870.938029  886.188605       0.624626                 0.390158   \n",
       "18  1880.450427  907.604548       0.622851                 0.387944   \n",
       "19  1885.683136  931.922788       0.626682                 0.392730   \n",
       "20     0.244333    0.115375       0.715338                 0.713277   \n",
       "21     0.118036    0.101084       0.707842                 0.707115   \n",
       "22     0.113713    0.098512       0.711285                 0.709215   \n",
       "23     0.118754    0.100632       0.709511                 0.707365   \n",
       "24     0.117454    0.096788       0.710748                 0.707504   \n",
       "25     6.889153    0.114615       0.774532                 0.771249   \n",
       "26     7.411511    0.135232       0.773234                 0.770320   \n",
       "27     7.263801    0.139516       0.773790                 0.770620   \n",
       "28     7.142239    0.134219       0.774770                 0.771628   \n",
       "29     7.350236    0.123278       0.772645                 0.769385   \n",
       "\n",
       "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
       "0               0.753211          0.744835      0.815798  LogReg  \n",
       "1               0.750377          0.742554      0.817177  LogReg  \n",
       "2               0.754800          0.747452      0.815897  LogReg  \n",
       "3               0.752576          0.744790      0.818429  LogReg  \n",
       "4               0.751907          0.744372      0.815377  LogReg  \n",
       "5               0.818206          0.817390      0.888723      RF  \n",
       "6               0.818550          0.817271      0.888333      RF  \n",
       "7               0.818947          0.817934      0.888986      RF  \n",
       "8               0.816882          0.815563      0.888003      RF  \n",
       "9               0.815129          0.814233      0.887621      RF  \n",
       "10              0.743703          0.738541      0.791959     KNN  \n",
       "11              0.741929          0.735912      0.792203     KNN  \n",
       "12              0.741690          0.736258      0.790189     KNN  \n",
       "13              0.741002          0.735659      0.789650     KNN  \n",
       "14              0.741207          0.735671      0.787422     KNN  \n",
       "15              0.626798          0.483005      0.804013     SVM  \n",
       "16              0.617316          0.471249      0.804780     SVM  \n",
       "17              0.624626          0.480304      0.804062     SVM  \n",
       "18              0.622851          0.478102      0.807386     SVM  \n",
       "19              0.626682          0.482860      0.803322     SVM  \n",
       "20              0.715338          0.693197      0.796196     GNB  \n",
       "21              0.707842          0.685745      0.791974     GNB  \n",
       "22              0.711285          0.688589      0.794803     GNB  \n",
       "23              0.709511          0.687073      0.793973     GNB  \n",
       "24              0.710748          0.688273      0.791422     GNB  \n",
       "25              0.774532          0.771316      0.842409     XGB  \n",
       "26              0.773234          0.769731      0.844397     XGB  \n",
       "27              0.773790          0.770719      0.843720     XGB  \n",
       "28              0.774770          0.771337      0.844614     XGB  \n",
       "29              0.772645          0.769632      0.842041     XGB  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# took a looooooong time to run, don't rerun :) \n",
    "\n",
    "run_experiments(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fd1baa23-1fbe-4f86-89bf-2ec56c92f514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial inspection looks like Random Forest is best bet... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dc48bd08-934b-4764-bbe8-ed38d3feac1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = Out[39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b648273a-0f15-4b32-8e00-ed4e1254cf76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
